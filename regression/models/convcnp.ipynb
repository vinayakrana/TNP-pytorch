{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convcnp(nn.Module):\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "    def forward(self,):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinayakrana/miniconda3/envs/tnp/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/vinayakrana/miniconda3/envs/tnp/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/home/vinayakrana/miniconda3/envs/tnp/lib/python3.9/site-packages/attrdict/mapping.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Mapping\n",
      "/home/vinayakrana/miniconda3/envs/tnp/lib/python3.9/site-packages/attrdict/mixins.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\n",
      "/home/vinayakrana/miniconda3/envs/tnp/lib/python3.9/site-packages/attrdict/mixins.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import neuralprocesses.torch as nps\n",
    "from attrdict import AttrDict\n",
    "\n",
    "class ConvCNP(torch.nn.Module):\n",
    "    def __init__(self, dim_x=1, dim_y=1, likelihood=\"het\"):\n",
    "\n",
    "        super(ConvCNP, self).__init__()\n",
    "        \n",
    "        self.model = nps.construct_convgnp(dim_x=dim_x, dim_y=dim_y, likelihood=likelihood)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "\n",
    "        xc, yc = batch.xc, batch.yc\n",
    "        xt, yt = batch.xt, batch.yt\n",
    "\n",
    "        # Adjust dimensions to match nps requirements\n",
    "        xc = xc.permute(0, 2, 1)\n",
    "        xt = xt.permute(0, 2, 1)\n",
    "        yc = yc.permute(0, 2, 1)\n",
    "        yt = yt.permute(0, 2, 1)\n",
    "\n",
    "        # Calculate loss\n",
    "        outs = AttrDict()\n",
    "        outs.tar_ll = nps.loglik(self.model, xc, yc, xt, yt, normalise=True)\n",
    "        outs.loss = -torch.mean(outs.tar_ll)\n",
    "        \n",
    "        # Return in the format expected by the framework\n",
    "        return outs\n",
    "\n",
    "    def predict(self, xc, yc, xt, num_samples=1):\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            xc = xc.permute(0, 2, 1)\n",
    "            xt = xt.permute(0, 2, 1)\n",
    "            yc = yc.permute(0, 2, 1)\n",
    "\n",
    "            mean, var, _, _ = nps.predict(self.model, xc, yc, xt)\n",
    "\n",
    "            # Match framework output format\n",
    "            return AttrDict(\n",
    "                mean=mean.permute(0, 2, 1),\n",
    "                scale=var.sqrt().permute(0, 2, 1)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import neuralprocesses.torch as nps\n",
    "from attrdict import AttrDict\n",
    "\n",
    "class ConvCNP(torch.nn.Module):\n",
    "    def __init__(self, dim_x=1, dim_y=1, likelihood=\"het\", device=None):\n",
    "        super(ConvCNP, self).__init__()\n",
    "\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = nps.construct_convgnp(dim_x=dim_x, dim_y=dim_y, likelihood=likelihood).to(self.device)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        xc, yc = batch.xc.to(self.device), batch.yc.to(self.device)\n",
    "        xt, yt = batch.xt.to(self.device), batch.yt.to(self.device)\n",
    "\n",
    "        # Adjust dimensions to match nps requirements\n",
    "        xc, xt = xc.permute(0, 2, 1), xt.permute(0, 2, 1)\n",
    "        yc, yt = yc.permute(0, 2, 1), yt.permute(0, 2, 1)\n",
    "\n",
    "        # Calculate loss\n",
    "        outs = AttrDict()\n",
    "        outs.tar_ll = nps.loglik(self.model, xc, yc, xt, yt, normalise=True)\n",
    "        outs.loss = -torch.mean(outs.tar_ll)\n",
    "        \n",
    "        return outs\n",
    "\n",
    "    def predict(self, xc, yc, xt, num_samples=1):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            xc, yc, xt = xc.to(self.device), yc.to(self.device), xt.to(self.device)\n",
    "            xc, xt = xc.permute(0, 2, 1), xt.permute(0, 2, 1)\n",
    "            yc = yc.permute(0, 2, 1)\n",
    "\n",
    "            mean, var, _, _ = nps.predict(self.model, xc, yc, xt)\n",
    "\n",
    "            return AttrDict(\n",
    "                mean=mean.permute(0, 2, 1),\n",
    "                scale=var.sqrt().permute(0, 2, 1)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loss: 1.1139764246647597\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'lab' has no attribute 'to_torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Run prediction\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Mean Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Scale Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;241m.\u001b[39mscale\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m, in \u001b[0;36mConvCNP.predict\u001b[0;34m(self, xc, yc, xt, num_samples)\u001b[0m\n\u001b[1;32m     31\u001b[0m xc, xt \u001b[38;5;241m=\u001b[39m xc\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m), xt\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m yc \u001b[38;5;241m=\u001b[39m yc\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m mean, var, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m AttrDict(\n\u001b[1;32m     37\u001b[0m     mean\u001b[38;5;241m=\u001b[39mmean\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     38\u001b[0m     scale\u001b[38;5;241m=\u001b[39mvar\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tnp/lib/python3.9/site-packages/neuralprocesses/model/predict.py:128\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, *args, **kw_args)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;129m@_dispatch\u001b[39m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(model: Model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[1;32m    127\u001b[0m     state \u001b[38;5;241m=\u001b[39m B\u001b[38;5;241m.\u001b[39mglobal_random_state(B\u001b[38;5;241m.\u001b[39mdtype(args[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m--> 128\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     state, res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m], res[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    130\u001b[0m     B\u001b[38;5;241m.\u001b[39mset_global_random_state(state)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tnp/lib/python3.9/site-packages/neuralprocesses/model/predict.py:122\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(state, model, xc, yc, xt, **kw_args)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;129m@_dispatch\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(state: B\u001b[38;5;241m.\u001b[39mRandomState, model: Model, xc, yc, xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw_args):\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tnp/lib/python3.9/site-packages/neuralprocesses/model/predict.py:68\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(state, model, contexts, xt, num_samples, batch_size, dtype_lik)\u001b[0m\n\u001b[1;32m     59\u001b[0m state, pred \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     60\u001b[0m     state,\n\u001b[1;32m     61\u001b[0m     contexts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39mthis_num_samples,\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(pred\u001b[38;5;241m.\u001b[39mvectorised_normal, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     mean_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_torch\u001b[49m(pred\u001b[38;5;241m.\u001b[39mvectorised_normal\u001b[38;5;241m.\u001b[39mmean)  \u001b[38;5;66;03m# Convert Dense to tensor\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred.vectorised_normal.mean device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_tensor\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(pred\u001b[38;5;241m.\u001b[39mvectorised_normal, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'lab' has no attribute 'to_torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from attrdict import AttrDict\n",
    "\n",
    "# Ensure CUDA is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Instantiate model\n",
    "model = ConvCNP(dim_x=1, dim_y=1, likelihood=\"het\", device=device)\n",
    "\n",
    "# Generate random batch data\n",
    "batch_size = 4\n",
    "num_context = 10\n",
    "num_target = 15\n",
    "dim_x = 1\n",
    "dim_y = 1\n",
    "\n",
    "batch = AttrDict(\n",
    "    xc=torch.randn(batch_size, num_context, dim_x).to(device),\n",
    "    yc=torch.randn(batch_size, num_context, dim_y).to(device),\n",
    "    xt=torch.randn(batch_size, num_target, dim_x).to(device),\n",
    "    yt=torch.randn(batch_size, num_target, dim_y).to(device),\n",
    ")\n",
    "\n",
    "\n",
    "# Run forward pass\n",
    "output = model(batch)\n",
    "print(f\"Loss: {output.loss.item()}\")\n",
    "\n",
    "# Run prediction\n",
    "predictions = model.predict(batch.xc, batch.yc, batch.xt)\n",
    "print(f\"Predicted Mean Shape: {predictions.mean.shape}\")\n",
    "print(f\"Predicted Scale Shape: {predictions.scale.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
