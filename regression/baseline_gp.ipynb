{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import MultivariateNormal, StudentT\n",
    "from attrdict import AttrDict\n",
    "import math\n",
    "from gp import gen_evalset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from utils.log import get_logger, RunningAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPSampler(object):\n",
    "    def __init__(self, kernel, t_noise=None, seed=None):\n",
    "        self.kernel = kernel\n",
    "        self.t_noise = t_noise\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed(seed)\n",
    "        self.seed = seed\n",
    "\n",
    "    def sample(self,\n",
    "            batch_size=16,\n",
    "            num_ctx=None,\n",
    "            num_tar=None,\n",
    "            max_num_points=50,\n",
    "            x_range=(-2, 2),\n",
    "            device='cpu'):\n",
    "\n",
    "        batch = AttrDict()\n",
    "        num_ctx = num_ctx or torch.randint(low=3, high=max_num_points-3, size=[1]).item()  # Nc\n",
    "        num_tar = num_tar or torch.randint(low=3, high=max_num_points-num_ctx, size=[1]).item()  # Nt\n",
    "\n",
    "        num_points = num_ctx + num_tar  # N = Nc + Nt\n",
    "        batch.x = x_range[0] + (x_range[1] - x_range[0]) \\\n",
    "                * torch.rand([batch_size, num_points, 1], device=device)  # [B,N,Dx=1]\n",
    "        batch.xc = batch.x[:,:num_ctx]  # [B,Nc,1]\n",
    "        batch.xt = batch.x[:,num_ctx:]  # [B,Nt,1]\n",
    "\n",
    "        # batch_size * num_points * num_points\n",
    "        cov, length, scale, noise_scale = self.kernel(batch.x)  # [B,N,N]\n",
    "        mean = torch.zeros(batch_size, num_points, device=device)  # [B,N]\n",
    "        batch.y = MultivariateNormal(mean, cov).rsample().unsqueeze(-1)  # [B,N,Dy=1]\n",
    "        batch.yc = batch.y[:,:num_ctx]  # [B,Nc,1]\n",
    "        batch.yt = batch.y[:,num_ctx:]  # [B,Nt,1]\n",
    "\n",
    "        if self.t_noise is not None:\n",
    "            if self.t_noise == -1:\n",
    "                t_noise = 0.15 * torch.rand(batch.y.shape).to(device)  # [B,N,1]\n",
    "            else:\n",
    "                t_noise = self.t_noise\n",
    "            batch.y += t_noise * StudentT(2.1).rsample(batch.y.shape).to(device)\n",
    "        return batch, length, scale, noise_scale\n",
    "        # {\"x\": [B,N,1], \"xc\": [B,Nc,1], \"xt\": [B,Nt,1],\n",
    "        #  \"y\": [B,N,1], \"yc\": [B,Nt,1], \"yt\": [B,Nt,1]}\n",
    "\n",
    "class RBFKernel(object):\n",
    "    def __init__(self, sigma_eps=2e-2, max_length=0.6, max_scale=1.0):\n",
    "        self.sigma_eps = sigma_eps\n",
    "        self.max_length = max_length\n",
    "        self.max_scale = max_scale\n",
    "\n",
    "    # x: batch_size * num_points * dim  [B,N,Dx=1]\n",
    "    def __call__(self, x):\n",
    "        length = 0.1 + (self.max_length-0.1) \\\n",
    "                * torch.rand([x.shape[0], 1, 1, 1], device=x.device)\n",
    "        scale = 0.1 + (self.max_scale-0.1) \\\n",
    "                * torch.rand([x.shape[0], 1, 1], device=x.device)\n",
    "\n",
    "        # batch_size * num_points * num_points * dim  [B,N,N,1]\n",
    "        dist = (x.unsqueeze(-2) - x.unsqueeze(-3))/length\n",
    "\n",
    "        # batch_size * num_points * num_points  [B,N,N]\n",
    "        cov = scale.pow(2) * torch.exp(-0.5 * dist.pow(2).sum(-1)) \\\n",
    "                + self.sigma_eps**2 * torch.eye(x.shape[-2]).to(x.device)\n",
    "\n",
    "        return cov, length, scale, self.sigma_eps  # [B,N,N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_evalset():\n",
    "    kernel = RBFKernel()\n",
    "\n",
    "    sampler = GPSampler(kernel, t_noise=None, seed=0)\n",
    "    batches = []\n",
    "    for i in tqdm(range(3000), ascii=True):\n",
    "        batches.append(sampler.sample(\n",
    "            batch_size=16,\n",
    "            max_num_points=50,\n",
    "            device='cuda'))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 3000/3000 [00:08<00:00, 355.50it/s]\n"
     ]
    }
   ],
   "source": [
    "batches = gen_evalset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('batches.pkl','wb') as f:\n",
    "#     pickle.dump(batches,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('batches.pkl','rb') as f:\n",
    "#     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "lls = []\n",
    "rmses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [08:54<00:00,  5.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(batches):\n",
    "    batch, length, scale, noise_scale = item\n",
    "    # print(length.shape)\n",
    "    curr_ll = []\n",
    "    curr_rmse = []\n",
    "    noise = noise_scale ** 2\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(noise))\n",
    "\n",
    "    for i in range(16):\n",
    "        model = ExactGPModel(batch.xc[i], batch.yc[i].ravel(), likelihood)\n",
    "        model.cuda()\n",
    "        # How to set params\n",
    "        model.covar_module.base_kernel.lengthscale = length[i]  # this is scale and not scale^2\n",
    "        model.covar_module.outputscale = scale[i] ** 2 # this is sigma^2 and not sigma\n",
    "        model.likelihood.noise = noise # this is sigma^2 and not sigma\n",
    "\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "        with torch.no_grad():\n",
    "            # print(f\"{batch.xt.shape=}\")\n",
    "            # print(batch.xc[0].shape, batch.xt[0].shape, batch.yc[0].ravel())\n",
    "            # observed_pred = model(batch.xt[i])\n",
    "            observed_pred = likelihood(model(batch.xt[i]))\n",
    "        # observed_pred is a Multi-variate normal distribution object, but we want to\n",
    "        # compute point-wise log likelihoods.\n",
    "        mean = observed_pred.mean\n",
    "        stddev = observed_pred.stddev\n",
    "        # print(batch.yt[i].shape)\n",
    "        # print(mean.shape)\n",
    "        oracle_log_likelihood = torch.distributions.Normal(mean, stddev).log_prob(batch.yt[i].ravel()).mean(-1)   \n",
    "\n",
    "        curr_ll.append(oracle_log_likelihood.item())\n",
    "        oracle_rmse = torch.sqrt(torch.mean((mean - batch.yt[i].ravel())**2))\n",
    "        curr_rmse.append(oracle_rmse.item())\n",
    "        \n",
    "        # print(f\"{oracle_rmse=}\")\n",
    "\n",
    "    lls.append(sum(curr_ll)/len(curr_ll))\n",
    "    rmses.append(sum(curr_rmse)/len(curr_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5369976595707293"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lls)/len(lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12042384587068228"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rmses)/len(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
