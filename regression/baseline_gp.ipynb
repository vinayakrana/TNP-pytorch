{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import MultivariateNormal, StudentT\n",
    "from attrdict import AttrDict\n",
    "import math\n",
    "from gp import gen_evalset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from utils.log import get_logger, RunningAverage\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from scipy.linalg import cholesky, cho_solve\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPSampler(object):\n",
    "    def __init__(self, kernel, t_noise=None, seed=None):\n",
    "        self.kernel = kernel\n",
    "        self.t_noise = t_noise\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed(seed)\n",
    "        self.seed = seed\n",
    "\n",
    "    def sample(self,\n",
    "            batch_size=16,\n",
    "            num_ctx=None,\n",
    "            num_tar=None,\n",
    "            max_num_points=50,\n",
    "            x_range=(-2, 2),\n",
    "            device='cpu'):\n",
    "\n",
    "        batch = AttrDict()\n",
    "        num_ctx = num_ctx or torch.randint(low=3, high=max_num_points-3, size=[1]).item()  # Nc\n",
    "        num_tar = num_tar or torch.randint(low=3, high=max_num_points-num_ctx, size=[1]).item()  # Nt\n",
    "\n",
    "        num_points = num_ctx + num_tar  # N = Nc + Nt\n",
    "        batch.x = x_range[0] + (x_range[1] - x_range[0]) \\\n",
    "                * torch.rand([batch_size, num_points, 1], device=device)  # [B,N,Dx=1]\n",
    "        batch.xc = batch.x[:,:num_ctx]  # [B,Nc,1]\n",
    "        batch.xt = batch.x[:,num_ctx:]  # [B,Nt,1]\n",
    "\n",
    "        # batch_size * num_points * num_points\n",
    "        cov, length, scale, noise_scale = self.kernel(batch.x)  # [B,N,N]\n",
    "        mean = torch.zeros(batch_size, num_points, device=device)  # [B,N]\n",
    "        batch.y = MultivariateNormal(mean, cov).rsample().unsqueeze(-1)  # [B,N,Dy=1]\n",
    "        batch.yc = batch.y[:,:num_ctx]  # [B,Nc,1]\n",
    "        batch.yt = batch.y[:,num_ctx:]  # [B,Nt,1]\n",
    "\n",
    "        if self.t_noise is not None:\n",
    "            if self.t_noise == -1:\n",
    "                t_noise = 0.15 * torch.rand(batch.y.shape).to(device)  # [B,N,1]\n",
    "            else:\n",
    "                t_noise = self.t_noise\n",
    "            batch.y += t_noise * StudentT(2.1).rsample(batch.y.shape).to(device)\n",
    "        return batch, length, scale, noise_scale\n",
    "        # {\"x\": [B,N,1], \"xc\": [B,Nc,1], \"xt\": [B,Nt,1],\n",
    "        #  \"y\": [B,N,1], \"yc\": [B,Nt,1], \"yt\": [B,Nt,1]}\n",
    "\n",
    "class RBFKernel(object):\n",
    "    def __init__(self, sigma_eps=2e-2, max_length=0.6, max_scale=1.0):\n",
    "        self.sigma_eps = sigma_eps\n",
    "        self.max_length = max_length\n",
    "        self.max_scale = max_scale\n",
    "\n",
    "    # x: batch_size * num_points * dim  [B,N,Dx=1]\n",
    "    def __call__(self, x):\n",
    "        length = 0.1 + (self.max_length-0.1) \\\n",
    "                * torch.rand([x.shape[0], 1, 1, 1], device=x.device)\n",
    "        scale = 0.1 + (self.max_scale-0.1) \\\n",
    "                * torch.rand([x.shape[0], 1, 1], device=x.device)\n",
    "\n",
    "        # batch_size * num_points * num_points * dim  [B,N,N,1]\n",
    "        dist = (x.unsqueeze(-2) - x.unsqueeze(-3))/length\n",
    "\n",
    "        # batch_size * num_points * num_points  [B,N,N]\n",
    "        cov = scale.pow(2) * torch.exp(-0.5 * dist.pow(2).sum(-1)) \\\n",
    "                + self.sigma_eps**2 * torch.eye(x.shape[-2]).to(x.device)\n",
    "\n",
    "        return cov, length, scale, self.sigma_eps  # [B,N,N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_evalset():\n",
    "    kernel = RBFKernel()\n",
    "\n",
    "    sampler = GPSampler(kernel, t_noise=None, seed=0)\n",
    "    batches = []\n",
    "    for i in tqdm(range(3000), ascii=True):\n",
    "        batches.append(sampler.sample(\n",
    "            batch_size=16,\n",
    "            max_num_points=50,\n",
    "            device='cuda'))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 3000/3000 [00:03<00:00, 793.61it/s]\n"
     ]
    }
   ],
   "source": [
    "batches = gen_evalset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('batches.pkl','wb') as f:\n",
    "#     pickle.dump(batches,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('batches.pkl','rb') as f:\n",
    "#     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lls = []\n",
    "rmses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:19<00:00,  7.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(batches):\n",
    "    batch, length, scale, noise_scale = item\n",
    "    # print(length.shape)\n",
    "    curr_ll = []\n",
    "    curr_rmse = []\n",
    "    noise = noise_scale ** 2\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(noise))\n",
    "\n",
    "    for i in range(16):\n",
    "        model = ExactGPModel(batch.xc[i], batch.yc[i].ravel(), likelihood)\n",
    "        model.cuda()\n",
    "        # How to set params\n",
    "        model.covar_module.base_kernel.lengthscale = length[i]  # this is scale and not scale^2\n",
    "        model.covar_module.outputscale = scale[i] ** 2 # this is sigma^2 and not sigma\n",
    "        model.likelihood.noise = noise # this is sigma^2 and not sigma\n",
    "\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "        with torch.no_grad():\n",
    "            # print(f\"{batch.xt.shape=}\")\n",
    "            # print(batch.xc[0].shape, batch.xt[0].shape, batch.yc[0].ravel())\n",
    "            # observed_pred = model(batch.xt[i])\n",
    "            observed_pred = likelihood(model(batch.xt[i]))\n",
    "        # observed_pred is a Multi-variate normal distribution object, but we want to\n",
    "        # compute point-wise log likelihoods.\n",
    "        mean = observed_pred.mean\n",
    "        stddev = observed_pred.stddev\n",
    "        # print(batch.yt[i].shape)\n",
    "        # print(mean.shape)\n",
    "        oracle_log_likelihood = torch.distributions.Normal(mean, stddev).log_prob(batch.yt[i].ravel()).mean(-1)   \n",
    "\n",
    "        curr_ll.append(oracle_log_likelihood.item())\n",
    "        oracle_rmse = torch.sqrt(torch.mean((mean - batch.yt[i].ravel())**2))\n",
    "        curr_rmse.append(oracle_rmse.item())\n",
    "        \n",
    "        # print(f\"{oracle_rmse=}\")\n",
    "\n",
    "    lls.append(sum(curr_ll)/len(curr_ll))\n",
    "    rmses.append(sum(curr_rmse)/len(curr_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5369976595707293"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lls)/len(lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12042384587068228"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rmses)/len(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try another implementation for verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src : https://gregorygundersen.com/blog/2019/09/12/practical-gp-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from   scipy.spatial.distance import pdist, cdist, squareform\n",
    "from   scipy.linalg import cholesky, cho_solve\n",
    "\n",
    "\n",
    "class GPRegressor:\n",
    "\n",
    "    def __init__(self, length_scale=1):\n",
    "        self.length_scale = length_scale\n",
    "        # In principle, this could be configurable.\n",
    "        self.kernel = rbf_kernel\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.kernel_ = self.kernel(X, length_scale=self.length_scale)\n",
    "        lower = True\n",
    "        L = cholesky(self.kernel_, lower=lower)\n",
    "        self.alpha_ = cho_solve((L, lower), y)\n",
    "        self.X_train_ = X\n",
    "        self.L_ = L\n",
    "\n",
    "    def predict(self, X):\n",
    "        K_star = self.kernel(X, self.X_train_, length_scale=self.length_scale)\n",
    "        y_mean = K_star.dot(self.alpha_)\n",
    "        lower = True\n",
    "        v = cho_solve((self.L_, lower), K_star.T)\n",
    "        y_cov = self.kernel(X, length_scale=self.length_scale) - K_star.dot(v)\n",
    "        return y_mean, y_cov\n",
    "\n",
    "\n",
    "def rbf_kernel(X, Y=None, length_scale=1):\n",
    "    if Y is None:\n",
    "        dists = pdist(X / length_scale, metric='sqeuclidean')\n",
    "        K = np.exp(-.5 * dists)\n",
    "        K = squareform(K)\n",
    "        np.fill_diagonal(K, 1)\n",
    "    else:\n",
    "        dists = cdist(X / length_scale, Y / length_scale, metric='sqeuclidean')\n",
    "        K = np.exp(-.5 * dists)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from scipy.linalg import cholesky, cho_solve\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "class GPRegressor:\n",
    "    def __init__(self, length_scale=1.0):\n",
    "        self.length_scale = length_scale\n",
    "        self.kernel = rbf_kernel\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.kernel_ = self.kernel(X, length_scale=self.length_scale)\n",
    "        lower = True\n",
    "        L = cholesky(self.kernel_, lower=lower)\n",
    "        self.alpha_ = cho_solve((L, lower), y)\n",
    "        self.X_train_ = X\n",
    "        self.L_ = L\n",
    "    # def fit(self, X, y):\n",
    "    #     self.kernel_ = self.kernel(X, length_scale=self.length_scale)\n",
    "    #     # Add jitter for numerical stability\n",
    "    #     self.kernel_ += 1e-6 * np.eye(len(self.kernel_))\n",
    "    #     lower = True\n",
    "    #     L = cholesky(self.kernel_, lower=lower)\n",
    "    #     self.alpha_ = cho_solve((L, lower), y)\n",
    "    #     self.X_train_ = X\n",
    "    #     self.L_ = L\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        K_star = self.kernel(X, self.X_train_, length_scale=self.length_scale)\n",
    "        y_mean = K_star.dot(self.alpha_)\n",
    "        lower = True\n",
    "        v = cho_solve((self.L_, lower), K_star.T)\n",
    "        y_cov = self.kernel(X, length_scale=self.length_scale) - K_star.dot(v)\n",
    "        return y_mean, y_cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lls = []\n",
    "rmses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:33<00:00, 88.95it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def rbf_kernel(X, Y=None, length_scale=1.0):\n",
    "    if Y is None:\n",
    "        dists = pdist(X / length_scale, metric='sqeuclidean')\n",
    "        K = np.exp(-0.5 * dists)\n",
    "        K = squareform(K)\n",
    "        np.fill_diagonal(K, 1)\n",
    "    else:\n",
    "        dists = cdist(X / length_scale, Y / length_scale, metric='sqeuclidean')\n",
    "        K = np.exp(-0.5 * dists)\n",
    "    return K\n",
    "\n",
    "\n",
    "class GPRegressor:\n",
    "    def __init__(self, length_scale=1.0):\n",
    "        self.length_scale = length_scale\n",
    "        self.kernel = rbf_kernel\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train_ = X\n",
    "        self.y_train_ = y\n",
    "        K = self.kernel(X, length_scale=self.length_scale)\n",
    "        # Add jitter\n",
    "        K += 1e-6 * np.eye(len(K))\n",
    "        self.L_ = cholesky(K, lower=True)\n",
    "        self.alpha_ = cho_solve((self.L_, True), y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        K_star = self.kernel(X, self.X_train_, length_scale=self.length_scale)\n",
    "        y_mean = K_star @ self.alpha_\n",
    "        v = cho_solve((self.L_, True), K_star.T)\n",
    "        K_ss = self.kernel(X, length_scale=self.length_scale)\n",
    "        y_cov = K_ss - K_star @ v\n",
    "        return y_mean, y_cov\n",
    "\n",
    "\n",
    "lls = []\n",
    "rmses = []\n",
    "\n",
    "for item in tqdm(batches):\n",
    "    batch, length, scale, noise_scale = item\n",
    "    curr_ll = []\n",
    "    curr_rmse = []\n",
    "\n",
    "    for i in range(16):  \n",
    "\n",
    "        model = GPRegressor(length_scale=length[i].item())\n",
    "\n",
    "        # Convert inputs to numpy\n",
    "        X_c = batch.xc[i].numpy()\n",
    "        y_c = batch.yc[i].numpy().ravel()\n",
    "        X_t = batch.xt[i].numpy()\n",
    "        y_t = batch.yt[i].numpy().ravel()\n",
    "\n",
    "        model.fit(X_c, y_c)\n",
    "\n",
    "        y_mean, y_cov = model.predict(X_t)\n",
    "        y_std = np.sqrt(np.clip(np.diag(y_cov), 1e-6, None))  # clip for numerical safety\n",
    "\n",
    "        # Compute log-likelihood\n",
    "        oracle_log_likelihood = norm.logpdf(y_t, loc=y_mean.ravel(), scale=y_std).mean()\n",
    "        curr_ll.append(oracle_log_likelihood)\n",
    "\n",
    "        # Compute RMSE\n",
    "        oracle_rmse = np.sqrt(np.mean((y_t - y_mean.ravel())**2))\n",
    "        curr_rmse.append(oracle_rmse)\n",
    "\n",
    "    lls.append(np.mean(curr_ll))\n",
    "    rmses.append(np.mean(curr_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7348.0016793345885"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lls)/len(lls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2880878969308954"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rmses) /len(rmses)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lls = []\n",
    "rmses = []\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:34<00:00, 86.95it/s]\n"
     ]
    }
   ],
   "source": [
    "def rbf_kernel(X, Y=None, length_scale=1.0, scale=1.0):\n",
    "    if Y is None:\n",
    "        dists = pdist(X / length_scale, metric='sqeuclidean')\n",
    "        K = np.exp(-0.5 * dists)\n",
    "        K = squareform(K)\n",
    "        np.fill_diagonal(K, 1.0)\n",
    "    else:\n",
    "        dists = cdist(X / length_scale, Y / length_scale, metric='sqeuclidean')\n",
    "        K = np.exp(-0.5 * dists)\n",
    "    return scale**2 * K\n",
    "\n",
    "\n",
    "class GPRegressor:\n",
    "    def __init__(self, length_scale=1.0, scale=1.0, noise_scale=1e-9):\n",
    "        self.length_scale = length_scale\n",
    "        self.scale = scale\n",
    "        self.noise_scale = noise_scale\n",
    "        self.kernel = rbf_kernel\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train_ = X\n",
    "        self.y_train_ = y\n",
    "        K = self.kernel(X, length_scale=self.length_scale, scale=self.scale)\n",
    "        K += self.noise_scale**2 * np.eye(len(K))  \n",
    "        self.L_ = cholesky(K, lower=True)\n",
    "        self.alpha_ = cho_solve((self.L_, True), y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        K_star = self.kernel(X, self.X_train_, length_scale=self.length_scale, scale=self.scale)\n",
    "        y_mean = K_star @ self.alpha_\n",
    "        v = cho_solve((self.L_, True), K_star.T)\n",
    "        K_ss = self.kernel(X, length_scale=self.length_scale, scale=self.scale)\n",
    "        y_cov = K_ss - K_star @ v\n",
    "        return y_mean, y_cov\n",
    "for item in tqdm(batches):\n",
    "    batch, length, scale, noise_scale = item\n",
    "    curr_ll = []\n",
    "    curr_rmse = []\n",
    "\n",
    "    for i in range(16):  \n",
    "        model = GPRegressor(length_scale=length[i].item(),\n",
    "                            scale=scale[i].item(),\n",
    "                            noise_scale=noise_scale)\n",
    "\n",
    "        X_c = batch.xc[i].numpy()\n",
    "        y_c = batch.yc[i].numpy().ravel()\n",
    "        X_t = batch.xt[i].numpy()\n",
    "        y_t = batch.yt[i].numpy().ravel()\n",
    "\n",
    "        model.fit(X_c, y_c)\n",
    "        y_mean, y_cov = model.predict(X_t)\n",
    "\n",
    "        y_std = np.sqrt(np.clip(np.diag(y_cov), 1e-9, None))\n",
    "\n",
    "        oracle_log_likelihood = norm.logpdf(y_t, loc=y_mean.ravel(), scale=y_std).mean()\n",
    "  \n",
    "        curr_ll.append(oracle_log_likelihood)\n",
    "\n",
    "        oracle_rmse = np.sqrt(np.mean((y_t - y_mean.ravel())**2))\n",
    "        curr_rmse.append(oracle_rmse)\n",
    "\n",
    "    lls.append(np.mean(curr_ll))\n",
    "    rmses.append(np.mean(curr_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-280027.0399803398"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lls)/len(lls)\n",
    "# sum(rmses) /len(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12411561695266496"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rmses) /len(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
